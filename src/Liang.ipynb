{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### READ DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "#####################################################################################################################\n",
    "# Data Processing Section\n",
    "# Helper function for preparing data for a decision tree classifiction problem. Parsing the data such\n",
    "# that for each feature, the property can only either be True or False. Label can only be 1 or 0.\n",
    "# For the chess.csv dataset won=1, nowin=0\n",
    "# In more detail:\n",
    "# Dataset with n instances, for each instance, there are m attributes. For the i-th attribute,\n",
    "# the property should be chosen from a set with size of m_i to represent the information.\n",
    "# Input: array with size of n*(m+1), the first column is the label\n",
    "# Output: array with size of n*(m_1 + m_2 + ... + m_m + 1), the first column is 1 or 0 corresponding to label\n",
    "#####################################################################################################################\n",
    "\n",
    "def get_data(filename, class_name, num_training, num_validation):\n",
    "    data = read_data(filename)\n",
    "    data = convert_to_binary_features(data, class_name)\n",
    "    return np.array(split_data(data, num_training, num_validation), dtype=object)\n",
    "\n",
    "def read_data(filename):\n",
    "    data = []\n",
    "    with open(filename) as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            data.append(row)\n",
    "    return data\n",
    "\n",
    "def convert_to_binary_features(data, class_name):\n",
    "    features = []\n",
    "    for feature_index in range(0, len(data[0])-1):\n",
    "        feature_values = list(set([obs[feature_index] for obs in data]))\n",
    "        feature_values.sort()\n",
    "        if len(feature_values) > 2: features.append(feature_values[:-1])\n",
    "        else: features.append([feature_values[0]])\n",
    "    new_data = []\n",
    "    for obs in data:\n",
    "        new_obs = [1 if obs[-1] == class_name else 0] # label = 1 if label in the dataset is won\n",
    "        for feature_index in range(0, len(data[0]) - 1):\n",
    "            current_feature_value = obs[feature_index]\n",
    "            for possible_feature_value in features[feature_index]:\n",
    "                new_obs.append(current_feature_value == possible_feature_value)\n",
    "        new_data.append(new_obs)\n",
    "\n",
    "    return new_data\n",
    "\n",
    "def split_data(data, num_training, num_validation):\n",
    "    random.shuffle(data)\n",
    "    # casting to a numpy array\n",
    "    data = np.array(data)\n",
    "    return data[0:num_training], data[num_training:num_training + num_validation], data[num_training + num_validation:len(data)]## **Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploring dataset: D:/DATA_2060/project/DATA2060_Final_Project/data/heartdvd.csv\n",
      "Gain Function: Gini Index\n",
      "  Unpruned Training Accuracy: 1.0000\n",
      "  Unpruned Test Accuracy: 0.9416\n",
      "Tree visualization saved as tree.png\n",
      "  Pruned Training Accuracy: 0.9707\n",
      "  Pruned Test Accuracy: 0.9221\n",
      "\n",
      "Using sklearn's DecisionTreeClassifier\n",
      "Sklearn Test Accuracy: 0.9578\n",
      "Sklearn decision tree saved as sklearn_tree.png.\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from graphviz import Digraph\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from graphviz import Source\n",
    "\n",
    "def node_score_gini(probabilities):\n",
    "    \"\"\"\n",
    "    Calculate the node score using the Gini index.\n",
    "    For datasets with multiple classes, Gini(p) = (1 - sum(p_i^2)) / (1 - 1/n_classes), normalized.\n",
    "    \"\"\"\n",
    "    gini = 1 - sum(p ** 2 for p in probabilities)\n",
    "    n_classes = len(probabilities)\n",
    "    if n_classes > 1:\n",
    "        gini /= (1 - 1 / n_classes)\n",
    "    return gini\n",
    "\n",
    "\n",
    "def visualize_tree(tree, filename=\"tree\"):\n",
    "    \"\"\"\n",
    "    Visualize the decision tree using Graphviz.\n",
    "    \"\"\"\n",
    "    def add_nodes_edges(dot, node, parent_id=None, edge_label=\"\"):\n",
    "        if node is None:\n",
    "            return\n",
    "\n",
    "        node_id = id(node)\n",
    "        if node.isleaf:\n",
    "            label = f\"Leaf: {node.label}\"\n",
    "        else:\n",
    "            label = f\"X[{node.index_split_on}] <= {node.threshold:.2f}\\nGain: {node.info.get('gain', 0):.4f}\"\n",
    "\n",
    "        dot.node(str(node_id), label)\n",
    "        if parent_id is not None:\n",
    "            dot.edge(str(parent_id), str(node_id), label=edge_label)\n",
    "\n",
    "        # Recursively add child nodes\n",
    "        add_nodes_edges(dot, node.left, node_id, edge_label=\"True\")\n",
    "        add_nodes_edges(dot, node.right, node_id, edge_label=\"False\")\n",
    "\n",
    "    # Create a Digraph object\n",
    "    dot = Digraph()\n",
    "    add_nodes_edges(dot, tree.root)\n",
    "\n",
    "    # Save and render the tree\n",
    "    dot.render(filename, format=\"png\", cleanup=True)\n",
    "    print(f\"Tree visualization saved as {filename}.png\")\n",
    "\n",
    "class Node:\n",
    "    \"\"\"\n",
    "    Helper to construct the tree structure.\n",
    "    \"\"\"\n",
    "    def __init__(self, left=None, right=None, depth=0, index_split_on=0, threshold=None, isleaf=False, label=None):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.depth = depth\n",
    "        self.index_split_on = index_split_on\n",
    "        self.threshold = threshold\n",
    "        self.isleaf = isleaf\n",
    "        self.label = label\n",
    "        self.info = {}\n",
    "\n",
    "    def set_info(self, gain, num_samples):\n",
    "        \"\"\"\n",
    "        Helper function to set node information for visualization.\n",
    "        \"\"\"\n",
    "        self.info['gain'] = gain\n",
    "        self.info['num_samples'] = num_samples\n",
    "\n",
    "class DecisionTree:\n",
    "\n",
    "    def __init__(self, gain_function=node_score_gini, max_depth=None, min_samples_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.gain_function = gain_function\n",
    "        self.root = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        data = [list(row) + [label] for row, label in zip(X, y)]\n",
    "        self.root = Node()\n",
    "        self._split_recursively(self.root, data, list(range(len(X[0]))))\n",
    "\n",
    "    def predict(self, X):\n",
    "        return [self._predict_recursive(self.root, row) for row in X]\n",
    "\n",
    "    def _predict_recursive(self, node, row):\n",
    "        if node.isleaf:\n",
    "            return node.label\n",
    "\n",
    "        if node.threshold is not None:\n",
    "            if row[node.index_split_on] <= node.threshold:\n",
    "                return self._predict_recursive(node.left, row)\n",
    "            else:\n",
    "                return self._predict_recursive(node.right, row)\n",
    "        else:\n",
    "            return self._predict_recursive(node.left if not row[node.index_split_on] else node.right, row)\n",
    "\n",
    "    def _is_terminal(self, node, data):\n",
    "        labels = [row[-1] for row in data]\n",
    "\n",
    "        # Stop splitting if one of the termination criteria is met\n",
    "        if len(set(labels)) == 1 or len(data) < self.min_samples_split or (self.max_depth is not None and node.depth >= self.max_depth):\n",
    "            node.isleaf = True\n",
    "            node.label = Counter(labels).most_common(1)[0][0]\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def _split_recursively(self, node, data, indices):\n",
    "        if self._is_terminal(node, data):\n",
    "            return\n",
    "\n",
    "        best_gain, best_index, best_threshold = -float('inf'), None, None\n",
    "\n",
    "        for index in indices:\n",
    "            gain, threshold = self._find_best_split(data, index)\n",
    "            if gain > best_gain:\n",
    "                best_gain, best_index, best_threshold = gain, index, threshold\n",
    "\n",
    "        if best_gain == -float('inf'):\n",
    "            node.isleaf = True\n",
    "            node.label = Counter(row[-1] for row in data).most_common(1)[0][0]\n",
    "            return\n",
    "\n",
    "        node.index_split_on = best_index\n",
    "        node.threshold = best_threshold\n",
    "\n",
    "        # Set node info with calculated gain and number of samples\n",
    "        node.set_info(gain=best_gain, num_samples=len(data))\n",
    "\n",
    "        left_data, right_data = self._split_data(data, best_index, best_threshold)\n",
    "\n",
    "        node.left = Node(depth=node.depth + 1)\n",
    "        node.right = Node(depth=node.depth + 1)\n",
    "        self._split_recursively(node.left, left_data, indices)\n",
    "        self._split_recursively(node.right, right_data, indices)\n",
    "\n",
    "    def _split_data(self, data, split_index, threshold):\n",
    "        if threshold is not None:\n",
    "            left_data = [row for row in data if row[split_index] <= threshold]\n",
    "            right_data = [row for row in data if row[split_index] > threshold]\n",
    "        else:\n",
    "            left_data = [row for row in data if row[split_index] == 0]\n",
    "            right_data = [row for row in data if row[split_index] == 1]\n",
    "        return left_data, right_data\n",
    "\n",
    "    def _find_best_split(self, data, split_index):\n",
    "        unique_values = sorted(set(row[split_index] for row in data))\n",
    "        best_gain, best_threshold = -float('inf'), None\n",
    "\n",
    "        if len(unique_values) > 10:\n",
    "            thresholds = np.linspace(unique_values[0], unique_values[-1], num=10)\n",
    "        else:\n",
    "            thresholds = [(unique_values[i - 1] + unique_values[i]) / 2 for i in range(1, len(unique_values))]\n",
    "\n",
    "        for threshold in thresholds:\n",
    "            left_data, right_data = self._split_data(data, split_index, threshold)\n",
    "\n",
    "            if left_data and right_data:\n",
    "                gain = self._calculate_gain(data, left_data, right_data)\n",
    "                if gain > best_gain:\n",
    "                    best_gain, best_threshold = gain, threshold\n",
    "\n",
    "        return best_gain, best_threshold\n",
    "\n",
    "    def _calculate_gain(self, parent_data, left_data, right_data):\n",
    "        total_count = len(parent_data)\n",
    "        left_count, right_count = len(left_data), len(right_data)\n",
    "\n",
    "        parent_probabilities = np.bincount([row[-1] for row in parent_data], minlength=2) / total_count\n",
    "        left_probabilities = np.bincount([row[-1] for row in left_data], minlength=2) / left_count\n",
    "        right_probabilities = np.bincount([row[-1] for row in right_data], minlength=2) / right_count\n",
    "\n",
    "        gain = self.gain_function(parent_probabilities)\n",
    "        gain -= (left_count / total_count) * self.gain_function(left_probabilities)\n",
    "        gain -= (right_count / total_count) * self.gain_function(right_probabilities)\n",
    "\n",
    "        return gain\n",
    "\n",
    "    def _prune_recursively(self, node, validation_data):\n",
    "        \"\"\"\n",
    "        Recursively prune the decision tree based on validation data.\n",
    "        \"\"\"\n",
    "        if node.isleaf:\n",
    "            return\n",
    "\n",
    "        # Prune children nodes first\n",
    "        if node.left:\n",
    "            self._prune_recursively(node.left, validation_data)\n",
    "        if node.right:\n",
    "            self._prune_recursively(node.right, validation_data)\n",
    "\n",
    "        # If both children are leaves, consider pruning them\n",
    "        if node.left.isleaf and node.right.isleaf:\n",
    "            current_loss = self._calculate_loss(validation_data)\n",
    "\n",
    "            # Temporarily make the current node a leaf\n",
    "            original_left, original_right = node.left, node.right\n",
    "            node.isleaf = True\n",
    "            node.label = Counter([row[-1] for row in validation_data]).most_common(1)[0][0]\n",
    "            node.left, node.right = None, None\n",
    "\n",
    "            new_loss = self._calculate_loss(validation_data)\n",
    "\n",
    "            # Revert if pruning increases loss\n",
    "            if new_loss > current_loss:\n",
    "                node.isleaf = False\n",
    "                node.left, node.right = original_left, original_right\n",
    "\n",
    "    def _calculate_loss(self, validation_data):\n",
    "        \"\"\"\n",
    "        Calculate the misclassification loss for the validation data.\n",
    "        \"\"\"\n",
    "        X_val = [row[:-1] for row in validation_data]\n",
    "        y_val = [row[-1] for row in validation_data]\n",
    "        predictions = self.predict(X_val)\n",
    "        return sum(pred != actual for pred, actual in zip(predictions, y_val)) / len(y_val)\n",
    "\n",
    "def explore_dataset(filename, class_name, train_ratio, validation_ratio):\n",
    "    def get_data_by_ratio(filename, class_name, train_ratio, validation_ratio):\n",
    "        df = pd.read_csv(filename)\n",
    "        df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "        total_rows = len(df)\n",
    "        train_end = int(total_rows * train_ratio)\n",
    "        validation_end = train_end + int(total_rows * validation_ratio)\n",
    "\n",
    "        train_data = df.iloc[:train_end].values.tolist()\n",
    "        validation_data = df.iloc[train_end:validation_end].values.tolist()\n",
    "        test_data = df.iloc[validation_end:].values.tolist()\n",
    "\n",
    "        return train_data, validation_data, test_data\n",
    "\n",
    "    train_data, validation_data, test_data = get_data_by_ratio(filename, class_name, train_ratio, validation_ratio)\n",
    "\n",
    "    gain_functions = {\"Gini Index\": node_score_gini}\n",
    "\n",
    "    print(f'Exploring dataset: {filename}')\n",
    "    for gain_name, gain_function in gain_functions.items():\n",
    "        print(f'Gain Function: {gain_name}')\n",
    "\n",
    "        # Build and evaluate unpruned tree\n",
    "        X_train = [row[:-1] for row in train_data]\n",
    "        y_train = [row[-1] for row in train_data]\n",
    "        X_test = [row[:-1] for row in test_data]\n",
    "        y_test = [row[-1] for row in test_data]\n",
    "\n",
    "        tree_unpruned = DecisionTree(gain_function=gain_function, max_depth=10)\n",
    "        tree_unpruned.fit(X_train, y_train)\n",
    "\n",
    "        train_accuracy_unpruned = sum(tree_unpruned.predict(X_train) == np.array(y_train)) / len(y_train)\n",
    "        test_accuracy_unpruned = sum(tree_unpruned.predict(X_test) == np.array(y_test)) / len(y_test)\n",
    "\n",
    "        print(f'  Unpruned Training Accuracy: {train_accuracy_unpruned:.4f}')\n",
    "        print(f'  Unpruned Test Accuracy: {test_accuracy_unpruned:.4f}')\n",
    "\n",
    "        # Build and evaluate pruned tree\n",
    "        X_val = [row[:-1] for row in validation_data]\n",
    "        y_val = [row[-1] for row in validation_data]\n",
    "\n",
    "        tree_pruned = DecisionTree(gain_function=gain_function, max_depth=10)\n",
    "        tree_pruned.fit(X_train, y_train)\n",
    "        tree_pruned._prune_recursively(tree_pruned.root, validation_data)\n",
    "\n",
    "        train_accuracy_pruned = sum(tree_pruned.predict(X_train) == np.array(y_train)) / len(y_train)\n",
    "        test_accuracy_pruned = sum(tree_pruned.predict(X_test) == np.array(y_test)) / len(y_test)\n",
    "        visualize_tree(tree_pruned)\n",
    "        print(f'  Pruned Training Accuracy: {train_accuracy_pruned:.4f}')\n",
    "        print(f'  Pruned Test Accuracy: {test_accuracy_pruned:.4f}')\n",
    "\n",
    "    # Train and visualize with sklearn DecisionTreeClassifier\n",
    "    print(\"\\nUsing sklearn's DecisionTreeClassifier\")\n",
    "    clf = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Visualize sklearn decision tree\n",
    "    dot_data = export_graphviz(\n",
    "        clf,\n",
    "        out_file=None,\n",
    "        feature_names=[f\"Feature {i}\" for i in range(len(X_train[0]))],\n",
    "        class_names=[str(cls) for cls in np.unique(y_train)],\n",
    "        filled=True,\n",
    "        rounded=True,\n",
    "        special_characters=True\n",
    "    )\n",
    "\n",
    "    graph = Source(dot_data)\n",
    "    graph.format = 'png'\n",
    "    graph.render('sklearn_tree', cleanup=True)\n",
    "    \n",
    "    test_accuracy_sklearn = clf.score(X_test, y_test)\n",
    "    print(f\"Sklearn Test Accuracy: {test_accuracy_sklearn:.4f}\")\n",
    "    print(\"Sklearn decision tree saved as sklearn_tree.png.\")\n",
    "\n",
    "# Usage example:\n",
    "explore_dataset('D:/DATA_2060/project/DATA2060_Final_Project/data/heartdvd.csv', 'target', train_ratio=0.5, validation_ratio=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DATA_2060",
   "language": "python",
   "name": "data_2060"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
